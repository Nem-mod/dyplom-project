import os
from dotenv import load_dotenv

from llama_index.core import Document, VectorStoreIndex

from llama_index.llms.openai import OpenAI

load_dotenv()

llm = OpenAI(
    model="gpt-3.5-turbo",
    temperature=0.3,
    api_key=os.getenv("OPENAI_API_KEY")
)

def generate_llm_report(summary: dict) -> str:
    stats = summary.get("statistics", {})
    corr = summary.get("correlations", {})
    anomalies = summary.get("anomalies", [])

    content = f"""
    üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats}
    üîó –ö–æ—Ä–µ–ª—è—Ü—ñ—ó: {corr}
    üö® –ê–Ω–æ–º–∞–ª—ñ—ó: {len(anomalies)} –∑–∞–ø–∏—Å—ñ–≤

    –°—Ñ–æ—Ä–º—É–π –∫–æ—Ä–æ—Ç–∫–∏–π –∞–Ω–∞–ª—ñ—Ç–∏—á–Ω–∏–π –±—ñ–∑–Ω–µ—Å-–∑–≤—ñ—Ç –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ü–∏—Ö –¥–∞–Ω–∏—Ö. –ó—Ä–æ–±–∏ –≤–∏—Å–Ω–æ–≤–∫–∏ —Ç–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó.
    """

    # –°—Ç–≤–æ—Ä—é—î–º–æ –¥–æ–∫—É–º–µ–Ω—Ç–∏
    documents = [Document(text=content)]

    # –ü—Ä–æ—Å—Ç–∏–π –≤–µ–∫—Ç–æ—Ä–Ω–∏–π —ñ–Ω–¥–µ–∫—Å (–º–æ–∂–Ω–∞ –∑–∞–º—ñ–Ω–∏—Ç–∏ –Ω–∞ Faiss —á–∏ —ñ–Ω—à–µ)
    index = VectorStoreIndex.from_documents(documents, llm=llm)

    # –í–∏–∫–æ–Ω—É—î–º–æ –∑–∞–ø–∏—Ç
    query_engine = index.as_query_engine()
    response = query_engine.query("–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π –¥–∞–Ω—ñ —ñ –∑–≥–µ–Ω–µ—Ä—É–π –±—ñ–∑–Ω–µ—Å-–∑–≤—ñ—Ç.")

    return str(response)
